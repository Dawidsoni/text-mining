{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    regex_match = re.search(\"([a-zA-Z]+)\", word)\n",
    "    if regex_match is None:\n",
    "        return None\n",
    "    return regex_match.group(1)\n",
    "\n",
    "\n",
    "def read_one_grams():\n",
    "    with open(\"1grams.txt\", \"r\") as file_stream:\n",
    "        one_grams = [clean_word(x.strip().split(\" \")[1]) for x in file_stream.readlines()]\n",
    "        return [x for x in one_grams if x is not None and len(x) > 0]\n",
    "    \n",
    "\n",
    "def read_words_base_forms():\n",
    "    words_base_forms = defaultdict(lambda: [])\n",
    "    with open(\"base_forms.txt\", \"r\") as fstream:\n",
    "        bases_words = map(lambda x: x.split(\";\")[0:2], fstream.readlines())\n",
    "        for base, word in bases_words:\n",
    "            words_base_forms[word].append(base)\n",
    "    return dict(words_base_forms)\n",
    "\n",
    "\n",
    "def fetch_corrections_words():\n",
    "    with open(\"literowki1.txt\") as file_stream:\n",
    "        return [x.strip().split(\" \") for x in file_stream.readlines()]\n",
    "    \n",
    "    \n",
    "def globalize_word(word):\n",
    "    constructed_chars = []\n",
    "    for character in word:\n",
    "        if character == \"ą\":\n",
    "            constructed_chars.append(\"a\")\n",
    "        elif character == \"ę\":\n",
    "            constructed_chars.append(\"e\")\n",
    "        elif character in [\"ż\", \"ź\"]:\n",
    "            constructed_chars.append(\"z\")\n",
    "        elif character == \"ś\":\n",
    "            constructed_chars.append(\"s\")\n",
    "        elif character == \"ó\":\n",
    "            constructed_chars.append(\"u\")\n",
    "        elif character == \"ć\":\n",
    "            constructed_chars.append(\"c\")        \n",
    "        elif character == \"ł\":\n",
    "            constructed_chars.append(\"l\")                    \n",
    "        elif character == \"ń\":\n",
    "            constructed_chars.append(\"n\")                                \n",
    "        else:\n",
    "            constructed_chars.append(character)\n",
    "    return \"\".join(constructed_chars)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4668625, 315689)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_base_forms = read_words_base_forms()\n",
    "words = set(words_base_forms.keys())\n",
    "base_forms = set(itertools.chain(*words_base_forms.values()))\n",
    "len(words), len(base_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections_words = fetch_corrections_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalized_words_original_words = {}\n",
    "for word in words:\n",
    "    globalized_word = globalize_word(word)\n",
    "    if globalized_word in globalized_words_original_words and word != globalized_word:\n",
    "        continue\n",
    "    globalized_words_original_words[globalized_word] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_words_original_words_ratings = {}\n",
    "for globalized_word, word in globalized_words_original_words.items():\n",
    "    for i in range(len(globalized_word)):\n",
    "        modified_word = f\"{globalized_word[:i]}{globalized_word[i + 1:]}\"\n",
    "        if modified_word in cut_words_original_words_ratings:\n",
    "            continue\n",
    "        cut_words_original_words_ratings[modified_word] = (word, 1)\n",
    "    cut_words_original_words_ratings[globalized_word] = (word, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_letter_neighbours(letter):\n",
    "    if letter == \"a\":\n",
    "        return {\"q\", \"w\", \"e\", \"d\", \"s\", \"z\", \"x\", \"c\", \"y\"}\n",
    "    elif letter == \"b\":\n",
    "        return {\"v\", \"f\", \"g\", \"h\", \"n\", \"m\", \"j\", \"c\"}\n",
    "    elif letter == \"c\":\n",
    "        return {\"z\", \"x\", \"v\", \"b\", \"s\", \"d\", \"f\", \"g\"}\n",
    "    elif letter == \"d\":\n",
    "        return {\"a\", \"s\", \"f\", \"g\", \"w\", \"e\", \"r\", \"x\", \"c\", \"v\"}\n",
    "    elif letter == \"e\":\n",
    "        return {\"q\", \"w\", \"r\", \"t\", \"a\", \"s\", \"d\", \"f\"}\n",
    "    elif letter == \"f\":\n",
    "        return {\"s\", \"d\", \"g\", \"h\", \"e\", \"r\", \"t\", \"c\", \"v\", \"b\", \"x\"}\n",
    "    elif letter == \"g\":\n",
    "        return {\"d\", \"f\", \"h\", \"j\", \"r\", \"t\", \"y\", \"c\", \"v\", \"b\", \"n\"}\n",
    "    elif letter == \"h\":\n",
    "        return {\"f\", \"g\", \"j\", \"k\", \"t\", \"y\", \"u\", \"v\", \"b\", \"n\", \"m\"}\n",
    "    elif letter == \"i\":\n",
    "        return {\"y\", \"u\", \"o\", \"p\", \"h\", \"j\", \"k\", \"l\"}\n",
    "    elif letter == \"j\":\n",
    "        return {\"g\", \"h\", \"k\", \"l\", \"y\", \"u\", \"i\", \"b\", \"n\", \"m\"}\n",
    "    elif letter == \"k\":\n",
    "        return {\"h\", \"j\", \"l\", \"u\", \"i\", \"o\", \"n\", \"m\"}\n",
    "    elif letter == \"l\":\n",
    "        return {\"p\", \"o\", \"i\", \"k\", \"j\", \"h\", \"m\", \"n\"}\n",
    "    elif letter == \"m\":\n",
    "        return {\"n\", \"b\", \"l\", \"k\", \"j\", \"h\", \"g\", \"i\"}\n",
    "    elif letter == \"n\":\n",
    "        return {\"v\", \"b\", \"m\", \"g\", \"h\", \"j\", \"k\", \"g\"}\n",
    "    elif letter == \"o\":\n",
    "        return {\"y\", \"u\", \"i\", \"p\", \"h\", \"j\", \"k\", \"l\"}\n",
    "    elif letter == \"p\":\n",
    "        return {\"u\", \"i\", \"o\", \"j\", \"k\", \"l\", \"h\", \"m\"}\n",
    "    elif letter == \"r\":\n",
    "        return {\"w\", \"e\", \"t\", \"y\", \"s\", \"d\", \"f\", \"g\"}\n",
    "    elif letter == \"s\":\n",
    "        return {\"a\", \"d\", \"f\", \"q\", \"w\", \"e\", \"r\", \"z\", \"x\", \"c\", \"v\"}\n",
    "    elif letter == \"t\":\n",
    "        return {\"e\", \"r\", \"y\", \"u\", \"d\", \"f\", \"g\", \"h\"}\n",
    "    elif letter == \"y\":\n",
    "        return {\"r\", \"t\", \"u\", \"i\", \"f\", \"g\", \"h\", \"j\"}\n",
    "    elif letter == \"u\":\n",
    "        return {\"t\", \"y\", \"i\", \"o\", \"g\", \"h\", \"j\", \"k\"}\n",
    "    elif letter == \"w\":\n",
    "        return {\"q\", \"e\", \"r\", \"t\", \"a\", \"s\", \"d\", \"f\"}\n",
    "    elif letter == \"x\":\n",
    "        return {\"z\", \"c\", \"v\", \"b\", \"a\", \"s\", \"d\", \"f\"}\n",
    "    elif letter == \"z\":\n",
    "        return {\"a\", \"s\", \"d\", \"f\", \"x\", \"c\", \"v\", \"q\"}\n",
    "    elif letter == \"q\":\n",
    "        return {\"a\", \"s\", \"d\", \"w\", \"e\", \"r\", \"f\", \"z\"}\n",
    "    elif letter == \"v\":\n",
    "        return {\"x\", \"c\", \"b\", \"n\", \"d\", \"f\", \"g\", \"h\"}    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid letter: {letter}\")\n",
    "    \n",
    "\n",
    "def get_word_modifications_weights(word):\n",
    "    modifications_weights = []\n",
    "    for i in range(1, len(word)):\n",
    "        modifications_weights.append((f\"{word[:i - 1]}{word[i]}{word[i - 1]}{word[i + 1:]}\", 1))\n",
    "    for i in range(2, len(word)):\n",
    "        modifications_weights.append((f\"{word[:i - 2]}{word[i]}{word[i - 1]}{word[i - 2]}{word[i + 1:]}\", 1))\n",
    "    for i in range(len(word)):\n",
    "        for letter in get_letter_neighbours(word[i]):\n",
    "            modifications_weights.append((f\"{word[:i]}{letter}{word[i + 1:]}\", 1.5))\n",
    "    for i in range(len(word)):\n",
    "        modifications_weights.append((f\"{word[:i]}{word[i + 1:]}\", 1))\n",
    "    return modifications_weights\n",
    "\n",
    "    \n",
    "def find_closest_word_rating(initial_word):\n",
    "    resolved_words = set()\n",
    "    words_steps_queue = deque([(initial_word, 0)])\n",
    "    closest_word = None\n",
    "    best_steps_count = np.inf\n",
    "    while len(words_steps_queue) > 0:\n",
    "        word, steps_count = words_steps_queue.popleft()\n",
    "        if word in cut_words_original_words_ratings:\n",
    "            candidate_word, steps_increase = cut_words_original_words_ratings[word]\n",
    "            if steps_count + steps_increase < best_steps_count:\n",
    "                best_steps_count = steps_count + steps_increase\n",
    "                closest_word = candidate_word                \n",
    "        if steps_count >= 5 or steps_count >= best_steps_count or len(resolved_words) >= 2_000_000:\n",
    "            break\n",
    "        modifications_weights = get_word_modifications_weights(word)\n",
    "        for modification, weight in modifications_weights:\n",
    "            if modification in resolved_words:\n",
    "                continue\n",
    "            words_steps_queue.append((modification, steps_count + weight))\n",
    "            resolved_words.add(modification)\n",
    "    return closest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(corrections_words):\n",
    "    positive_counter = 0\n",
    "    for correction, word in corrections_words:\n",
    "        if correction == find_closest_word_rating(globalize_word(word)):\n",
    "            positive_counter += 1\n",
    "    return positive_counter / len(corrections_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7024793388429752"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(corrections_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'korektorek'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_closest_word_rating(globalize_word(corrections_words[21][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
