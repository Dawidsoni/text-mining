{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import functools\n",
    "import string\n",
    "import termcolor\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_quotes():\n",
    "    with open(\"cytaty.txt\", \"r\") as fstream:\n",
    "        return list(map(lambda x: x.strip(), fstream.readlines()))\n",
    "\n",
    "\n",
    "def read_words_base_forms():\n",
    "    words_base_forms = defaultdict(lambda: [])\n",
    "    with open(\"base_forms.txt\", \"r\") as fstream:\n",
    "        bases_words = map(lambda x: x.split(\";\")[0:2], fstream.readlines())\n",
    "        for base, word in bases_words:\n",
    "            words_base_forms[word].append(base)\n",
    "    return dict(words_base_forms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_prefix_of_quote(quote):\n",
    "    FILTERED_CHAR_CODES = set([8211])\n",
    "    for i in range(len(quote)):\n",
    "        if quote[i] == \" \" or quote[i] in string.punctuation:\n",
    "            continue\n",
    "        if ord(quote[i]) in FILTERED_CHAR_CODES:\n",
    "            continue\n",
    "        return quote[i:]\n",
    "    return quote\n",
    "\n",
    "\n",
    "def clean_quote_numbers(quote):\n",
    "    regex_match = re.match(\"([\\d]*\\.[\\d\\s\\.]*)(.*)\", quote)\n",
    "    if regex_match is None:\n",
    "        return quote\n",
    "    return regex_match.group(2)\n",
    "\n",
    "\n",
    "def clean_html_suffix(quote, regex):\n",
    "    regex_match = re.match(regex, quote)\n",
    "    if regex_match is None:\n",
    "        return quote\n",
    "    return regex_match.group(1)\n",
    "\n",
    "\n",
    "def fix_punctuation(quote):\n",
    "    if len(quote) == 0 or quote[-1] in set([\"?\", \"!\", \".\"]):\n",
    "        return quote\n",
    "    return f\"{quote}.\"\n",
    "\n",
    "\n",
    "def clean_quote(quote):\n",
    "    quote = clean_prefix_of_quote(quote)\n",
    "    quote = clean_quote_numbers(quote)\n",
    "    quote = clean_html_suffix(quote, regex=\"(.*?)&lt;(.*)\")\n",
    "    quote = clean_html_suffix(quote, regex=\"(.*?)&gt;(.*)\")\n",
    "    return fix_punctuation(quote)\n",
    "\n",
    "    \n",
    "def split_on_regex_subquotes(quote, regex, next_part_group):\n",
    "    subquotes = []\n",
    "    while True:\n",
    "        match = re.match(regex, quote)\n",
    "        if match is None:\n",
    "            break\n",
    "        subquotes.append(match.group(1))\n",
    "        quote = match.group(next_part_group)\n",
    "    subquotes.append(quote)\n",
    "    return subquotes\n",
    "\n",
    "\n",
    "def split_on_subquotes(quote):\n",
    "    sentence_subquotes = split_on_regex_subquotes(quote, regex=\"(.*?)&lt;(.*?)&gt; ([A-Z](.*))\", next_part_group=3)\n",
    "    return itertools.chain(*map(\n",
    "        lambda x: split_on_regex_subquotes(x, regex=\"(.*?)\\. ([A-Z](.*))\", next_part_group=2),\n",
    "        sentence_subquotes\n",
    "    ))\n",
    "\n",
    "\n",
    "def is_quote_accepted(quote):\n",
    "    MIN_QUOTE_LENGTH = 4\n",
    "    return len(quote.split(\" \")) >= MIN_QUOTE_LENGTH\n",
    "\n",
    "\n",
    "def get_formatted_quotes(quotes):\n",
    "    subquotes = itertools.chain(*map(split_on_subquotes, quotes))\n",
    "    cleaned_subquotes = map(clean_quote, subquotes)\n",
    "    filtered_subquotes = filter(is_quote_accepted, cleaned_subquotes)\n",
    "    return list(filtered_subquotes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quotes index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuotesIndex(object):\n",
    "    \n",
    "    def __init__(self, words_base_forms, quotes):\n",
    "        self.words_base_forms = words_base_forms\n",
    "        self.quotes = quotes\n",
    "        self.index_of_quotes = self._generate_index_of_quotes()\n",
    "        self.word_scores = self._generate_word_scores()\n",
    "        \n",
    "    @staticmethod\n",
    "    def _clean_word(word):\n",
    "        regex_match = re.match(\"[^a-z]*([a-z]*)[^a-z]*\", word)\n",
    "        return regex_match.group(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _tokenize_sentence(sentence):\n",
    "        return [QuotesIndex._clean_word(x) for x in sentence.lower().split(' ')]\n",
    "\n",
    "    def _generate_word_scores(self):\n",
    "        SCORE_MULTIPLIER = 5\n",
    "        word_counter = Counter()\n",
    "        word_scores = {}\n",
    "        for quote in self.quotes:\n",
    "            base_forms = self._generate_base_forms(quote)\n",
    "            for base_form in base_forms:\n",
    "                word_counter[base_form] += 1\n",
    "        max_word_count = max(word_counter.values())\n",
    "        for word in word_counter.keys():\n",
    "            word_scores[word] = np.exp(-(word_counter[word] / max_word_count) * SCORE_MULTIPLIER)\n",
    "        return defaultdict(lambda: 1.0, word_scores)\n",
    "        \n",
    "    def _generate_base_forms(self, sentence):\n",
    "        words = QuotesIndex._tokenize_sentence(sentence)\n",
    "        base_forms = []\n",
    "        for word in words:\n",
    "            if word in self.words_base_forms:\n",
    "                base_forms.extend(self.words_base_forms[word])\n",
    "            else:\n",
    "                base_forms.append(word)\n",
    "        return set(base_forms)\n",
    "\n",
    "    def _generate_index_of_quotes(self):\n",
    "        index_of_quotes = defaultdict(lambda: set())\n",
    "        for index, quote in enumerate(self.quotes):\n",
    "            base_forms = self._generate_base_forms(quote)\n",
    "            for base_form in base_forms:\n",
    "                index_of_quotes[base_form].add(index)\n",
    "        return index_of_quotes\n",
    "\n",
    "    def _generate_document_indexes_scores(self, query):\n",
    "        words = QuotesIndex._tokenize_sentence(query)\n",
    "        word_base_forms = {x: self._generate_base_forms(x) for x in words}\n",
    "        indexes_scores = defaultdict(lambda: 0)\n",
    "        for word, base_forms in word_base_forms.items():\n",
    "            base_forms_matching_indexes = {x: self.index_of_quotes[x] for x in base_forms}\n",
    "            if len(base_forms_matching_indexes) == 0:\n",
    "                continue\n",
    "            for base_form, matching_indexes in base_forms_matching_indexes.items():                \n",
    "                for matching_index in matching_indexes:\n",
    "                    indexes_scores[matching_index] += self.word_scores[base_form]\n",
    "        return indexes_scores\n",
    "    \n",
    "    def get_documents_scores(self, query):\n",
    "        indexes_scores = self._generate_document_indexes_scores(query)\n",
    "        return {self.quotes[index]: indexes_scores[index] for index in indexes_scores.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(quotes_index, query, past_answers):\n",
    "    DEFAULT_QUERY = \"Być albo nie być.\"\n",
    "    documents_scores = quotes_index.get_documents_scores(query)\n",
    "    for document in documents_scores.keys():\n",
    "        if document in past_answers:\n",
    "            del documents_scores[document]\n",
    "    if len(documents_scores) == 0 and query == DEFAULT_QUERY: \n",
    "        return DEFAULT_QUERY\n",
    "    if len(documents_scores) == 0:\n",
    "        return generate_answer(quotes_index, query=DEFAULT_QUERY, past_answers=past_answers)\n",
    "    documents, scores = zip(*documents_scores.items())\n",
    "    boosted_scores = np.power(scores, 10)\n",
    "    normalized_scores = boosted_scores / np.sum(boosted_scores)\n",
    "    return np.random.choice(documents, p=normalized_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = get_formatted_quotes(read_quotes())\n",
    "words_base_forms = read_words_base_forms()\n",
    "quotes_index = QuotesIndex(words_base_forms, quotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Ładna dziś pogoda.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mBank jest miejscem, w którym pożyczają ci parasol wówczas, gdy jest ładna pogoda, i proszą o jego zwrot, gdy zaczyna padać deszcz.\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Więc poszedłeś dziś do banku?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTo było wielkie świństwo wobec pracowników PGR, że nie zostali dopuszczeni do prywatyzacji – jak pracownicy banków czy innych przedsiębiorstw.\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " O jakiej sytuacji mówisz?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mGeniusz Bruke'a polegał na tym, że pojął przesłanki i konsekwencje takiego sposobu myślenia, jaki wyraził się w hasłach i w dokonaniach rewolucji francuskiej, reagując więc na to doświadczenie, upierał się przy twierdzeniu, że tam gdzie chodzi o sprawy człowieka, nic nie istnieje „w ogóle”, a tylko w szczegółach, abstrakcyjne zaś myślenie jest najgorszą z możliwych wskazówek postępowania.\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Widzę, że znasz się na historii francuskiej.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mHistoria Rasputina oraz fakt, że do jego zamordowania przyznał się książę Jusupow, są powszechnie znane.\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Ja nie słyszałem o tym fakcie.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mDyskusję o miejscu pochówku głowy państwa prowokuje dziś to samo środowisko, które sześć lat temu w najostrzejszych słowach oburzało się zadawaniem pytań, czy Czesław Miłosz powinien spocząć na krakowskiej Skałce.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "past_answers = set()\n",
    "while True:\n",
    "    query = input()\n",
    "    answer = generate_answer(quotes_index, query, past_answers)\n",
    "    print(termcolor.colored(answer, \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.51627405e+04, 5.51627405e+04, 1.58854641e+03, ...,\n",
       "       1.89363829e-10, 1.89363829e-10, 1.89363829e-10])"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(sorted(quotes_index.get_documents_scores(\"Pilot jest pijany.\").values(), reverse=True), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Drzewo nie jest podmiotem.'"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
